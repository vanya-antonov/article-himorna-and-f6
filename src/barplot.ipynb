{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#У нас есть данные о связи lncRNA с участками генома - их можно проассоциировать с генами\n",
    "#У фантома есть даные о дифф экспрессии генов после нокаута lncRNA - как бы эта РНК регулирует эти гены\n",
    "#Или надо отобрать те гены, которые начали экспрессироваться после нокаута lncRNA?\n",
    "# Что мы можем сделать?\n",
    "#Мы должны взять из фантомных данных список генов, которые диффэкспрессируются у конкретной РНК и сравнить его\n",
    "#с нашим списком генов для этой РНК - по идее они должны сильно пересекаться"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.core.display import display, HTML\n",
    "# display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install statsmodels\n",
    "#!pip install bcbio-gff\n",
    "#!pip install mygene\n",
    "#!pip install h5py\n",
    "#!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import scipy.stats as stats\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "from BCBio import GFF\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqUtils import GC\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.SeqFeature import SeqFeature, FeatureLocation\n",
    "import mygene\n",
    "import h5py\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.colors import LinearSegmentedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [(\"H3K27ac\", \"_narrow\"), (\"H3K36me3\", \"\"), \n",
    "           (\"H3K4me1\", \"_narrow\"), (\"H3K4me2\", \"_narrow\"), (\"H3K4me3\", \"_narrow\"), (\"H3K79me2\", \"\"), \n",
    "           (\"H3K9ac\", \"_narrow\"), (\"H3K9me3\", \"\"), (\"H4K20me1\", \"\"), (\"H3K27me3\", \"\"), (\"methylation\", \"\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Строим таблицу, где строки это все возможные lnc, для которых есть хотя бы одно значимое пересечение хотя бы для одной метки\n",
    "#а столбцы мультииндекс по метке и по типу\n",
    "def getTableForAllMarks(iMARGI=False, annotation_prefix=\"\"):\n",
    "    g_annotation_prefix = annotation_prefix + \"_\" if annotation_prefix else \"\"\n",
    "    annotation_prefix = \"_\" + annotation_prefix if annotation_prefix else \"\"\n",
    "    \n",
    "    df_first = pd.read_csv(\"../data/all_marks/\" + targets[0][0] + \"/our_fantom\" + annotation_prefix + \"_genes_association_pvalues.tsv\", sep=\"\\t\")\n",
    "    df_first['lncRNAName'] = [\"_\".join([name] + i.split('_')[1:]) for i, name in zip(df_first['lncRNAId'], df_first['lncRNAName'])]\n",
    "    if(iMARGI):\n",
    "        g = pd.read_csv(\"../data/all_marks/\" + targets[0][0] + \"/\" + g_annotation_prefix + \"genometric_result_all_rnas.tsv\", sep=\"\\t\")\n",
    "        df_first = df_first[df_first['lncRNAId'].isin(g['lnc'])][['lncRNAName', 'pm_pvalue', 'mm_pvalue', 'pp_pvalue', 'mp_pvalue']]\n",
    "    else:\n",
    "        df_first = df_first[['lncRNAName', 'pm_pvalue', 'mm_pvalue', 'pp_pvalue', 'mp_pvalue']]\n",
    "        \n",
    "    for i in range(1, len(targets)):\n",
    "        df_second = pd.read_csv(\"../data/all_marks/\" + targets[i][0] + \"/our_fantom\" + annotation_prefix + \"_genes_association_pvalues.tsv\", sep=\"\\t\")\n",
    "        df_second['lncRNAName'] = [\"_\".join([name] + i.split('_')[1:]) for i, name in zip(df_second['lncRNAId'], df_second['lncRNAName'])]\n",
    "        if(iMARGI):\n",
    "            g = pd.read_csv(\"../data/all_marks/\" + targets[i][0] + \"/\" + g_annotation_prefix + \"genometric_result_all_rnas.tsv\", sep=\"\\t\")\n",
    "            df_second = df_second[df_second['lncRNAId'].isin(g['lnc'])][['lncRNAName', 'pm_pvalue', 'mm_pvalue', 'pp_pvalue', 'mp_pvalue']]\n",
    "        else:\n",
    "            df_second = df_second[['lncRNAName', 'pm_pvalue', 'mm_pvalue', 'pp_pvalue', 'mp_pvalue']]\n",
    "            \n",
    "        df_first = df_first.merge(df_second, how=\"outer\", left_on='lncRNAName', right_on='lncRNAName')\n",
    "    \n",
    "    df_first = df_first.set_index('lncRNAName')\n",
    "    # del df_first.index.name\n",
    "    df_first = df_first.applymap(lambda x: 0 if np.isnan(x) else -np.log10(x))\n",
    "    columns_index_1 = [\"H3K27ac\", \"H3K36me3\", \"H3K4me1\", \"H3K4me2\", \"H3K4me3\", \"H3K79me2\", \"H3K9ac\", \"H3K9me3\", \"H4K20me1\", \"H3K27me3\", \"Methylation\"]\n",
    "    columns_index_2 = ['wa', 'ea', 'wr', 'er']\n",
    "    df_first.columns = pd.MultiIndex.from_product([columns_index_1, columns_index_2], names=['target', 'type'])\n",
    "    \n",
    "    np.unravel_index(np.argmax(df_first.values, axis=None), df_first.values.shape)\n",
    "    \n",
    "    #df_first = df_first.drop('EMX2OS')\n",
    "    \n",
    "    return df_first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataWithoutASOs(iMARGI=False, clusters=False):\n",
    "    df = getTableForAllMarks(iMARGI=iMARGI, annotation_prefix=\"fantom_aso\")\n",
    "    df = df.mask(df < 1.3, 0)\n",
    "    df['geneName'] = [i.split('_')[0] for i in df.index]\n",
    "    b = df.groupby(['geneName']).apply(check_asos)\n",
    "    b = b.drop(['geneName'], axis=1)\n",
    "    b = b[b.astype(bool).sum(axis=1) > 0]\n",
    "    if clusters:\n",
    "        return b.apply(add_cluster, axis = 1, result_type=\"expand\")\n",
    "    else:\n",
    "        return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_asos(df):\n",
    "    count = pd.DataFrame({\"nonzero_count\" : df.astype(bool).sum(axis=0)})['nonzero_count']\n",
    "    if df.shape[0] == 1:  # Нет нескольких ASO - 1\n",
    "        return count\n",
    "    else:\n",
    "        s = pd.Series([2 if b else 0 for b in count > df.shape[0]/2], index=count.index)\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_1 = getDataWithoutASOs(iMARGI=True)\n",
    "df1_2 = getDataWithoutASOs(iMARGI=True)\n",
    "df1_1[df1_1 > 1] = 0\n",
    "df1_2[df1_2 == 1] = 0\n",
    "df1_2[df1_2 > 1] = 1\n",
    "\n",
    "df2_1 = getDataWithoutASOs(iMARGI=False)\n",
    "df2_2 = getDataWithoutASOs(iMARGI=False)\n",
    "df2_1[df2_1 > 1] = 0\n",
    "df2_2[df2_2 == 1] = 0\n",
    "df2_2[df2_2 > 1] = 1\n",
    "\n",
    "df1_1['sum'] = df1_1.sum(axis=1)\n",
    "df1_2['sum'] = df1_2.sum(axis=1)\n",
    "\n",
    "df2_1['sum'] = df2_1.sum(axis=1)\n",
    "df2_2['sum'] = df2_2.sum(axis=1)\n",
    "\n",
    "sum_1 = pd.DataFrame({\"gene\": df1_1.index, \"ASO_1\": df1_1['sum'], \"ASO_>1\": df1_2['sum']})\n",
    "sum_2 = pd.DataFrame({\"gene\": df2_1.index, \"ASO_1\": df2_1['sum'], \"ASO_>1\": df2_2['sum']})\n",
    "\n",
    "sum_1['IMARGI'] = \"TRUE\"\n",
    "sum_1['INDEXES'] = sum_1['gene'].astype(str) +\"_\"+ sum_1[\"IMARGI\"]\n",
    "sum_1 = sum_1.reset_index(drop=True)\n",
    "sum_1 = sum_1[['INDEXES', 'ASO_1', 'ASO_>1']]\n",
    "\n",
    "sum_2['IMARGI'] = \"FALSE\"\n",
    "sum_2['INDEXES'] = sum_2['gene'].astype(str) +\"_\"+ sum_2[\"IMARGI\"]\n",
    "sum_2 = sum_2.reset_index(drop=True)\n",
    "sum_2 = sum_2[['INDEXES', 'ASO_1', 'ASO_>1']]\n",
    "\n",
    "sum_0 = pd.concat([sum_1, sum_2])\n",
    "sum_0 = sum_0.sort_values(by=['INDEXES'], ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = ['ASO_1', 'ASO_>1']\n",
    "colors = [\"#127d72\", \"#d93079\"]\n",
    "labels = ['ASO = 1', 'ASO > 1']# figure and axis\n",
    "rcParams['figure.figsize'] = 25,28\n",
    "rcParams[\"patch.force_edgecolor\"] = True\n",
    "fig, ax = plt.subplots(1, figsize=(20, 20))# plot bars\n",
    "left = len(sum_0) * [0]\n",
    "for idx, name in enumerate(fields):\n",
    "    plt.barh(sum_0['INDEXES'], sum_0[name], left = left, color=colors[idx])\n",
    "    left = left + sum_0[name]# title, legend, labels\n",
    "plt.title('Title', loc='left', fontsize='xx-large')\n",
    "plt.legend(labels, loc='upper right', bbox_to_anchor=(0.5, 0.53, 0.5, 0.5), ncol=2, fontsize='xx-large', frameon=False)\n",
    "plt.xlabel('Number of associations', fontsize='x-large')\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)# adjust limits and draw grid lines\n",
    "plt.ylim(-0.5, ax.get_yticks()[-1] + 0.5)\n",
    "ax.set_axisbelow(True)\n",
    "ax.xaxis.grid(color='gray', linestyle='dashed')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = ax.get_figure()\n",
    "#fig.patch.set_alpha(0)\n",
    "fig.savefig(\"../images/barplot.png\", bbox_inches='tight', pad_inches =0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "dd38bd7452461f122cef87efd02354cfd42d25e75ea2d6193837b6cd0d10b18a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
